@article{Trilling2016,
  author  = {Trilling, Damian},
  url     = {http://papers.ssrn.com/abstract=2737682},
  year    = {2019},
  journal = {SSRN},
  title   = {Doing Computational Social Science with {P}ython: {A}n Introduction. {V}ersion 1.3}
}

@article{freelon_computational_2018,
  author   = {Freelon, Deen},
  url      = {https://doi.org/10.1080/10584609.2018.1477506},
  year     = {2018-10},
  doi      = {10.1080/10584609.2018.1477506},
  issn     = {1058-4609},
  journal  = {Political Communication},
  keywords = {API,computational,Facebook,social media,Twitter},
  number   = {4},
  pages    = {665--668},
  title    = {Computational research in the post-{API} age},
  urlyear  = {2023-08-21},
  volume   = {35}
}

@incollection{Trilling2017a,
  author    = {Trilling, Damian},
  editor    = {Matthes, Jörg and Davis, Christine S. and Potter, Robert F.},
  publisher = {Wiley},
  booktitle = {The International Encyclopedia of Communication Research Methods},
  year      = {2017},
  doi       = {10.1002/9781118901731.iecrm0014},
  isbn      = {9781118901731},
  title     = {{Big Data, Analysis of}}
}

@incollection{Guenther2018,
  author    = {Günther, Elisabeth and Trilling, Damian and {Van de Velde}, Robert Nicolai},
  editor    = {Stuetzer, C. M. and Welker, M. and Egger, M.},
  location  = {Cologne, Germany},
  publisher = {von Halem},
  booktitle = {Computational Social Science in the Age of {Big Data}. {C}oncepts, Methodologies, Tools, and Applications},
  year      = {2018},
  title     = {But how do we store it? {(Big)} data architecture in the social-scientic research process}
}

@article{scikit-learn,
  author  = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year    = {2011},
  journal = {Journal of Machine Learning Research},
  pages   = {2825--2830},
  title   = {Scikit-learn: Machine Learning in {P}ython},
  volume  = {12}
}

@inproceedings{Maas2011,
  author    = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher},
  location  = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  url       = {http://www.aclweb.org/anthology/P11-1015},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2011},
  pages     = {142--150},
  title     = {Learning Word Vectors for Sentiment Analysis}
}

@inproceedings{Rehurek2010,
  author    = {Řehůřek, Radim and Sojka, Petr},
  language  = {English},
  location  = {Valletta, Malta},
  publisher = {ELRA},
  booktitle = {{Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks}},
  year      = {2010},
  note      = {\url{http://is.muni.cz/publication/884893/en}},
  pages     = {45--50},
  title     = {Software Framework for Topic Modelling with Large Corpora}
}

@article{Thelwall2012,
  author  = {Thelwall, Mike and Buckley, Kevan and Paltoglou, Georgios},
  year    = {2012},
  doi     = {10.1002/asi.21662},
  issn    = {1532-2890},
  journal = {Journal of the American Society for Information Science and Technology},
  number  = {1},
  pages   = {163--173},
  title   = {Sentiment strength detection for the social web},
  volume  = {63}
}

@inproceedings{Ellison2013,
  abstract  = {Past research suggests Facebook use is linked to perceptions of social capital, a concept that taps into the resources people gain from interactions with their social network. In this study, we examine a sample of public Facebook status upyears (N=20,000) for instances in which users request a response from their network. These attempts to mobilize resources offer insight into the mechanisms through which Facebook is used for social capital conversion. After identifying mobilization requests (N=856), we categorize them by cost (i.e., effort needed to satisfy the request) and type (e.g., opinion, information, social coordination) in order to describe the prevalence of these requests and the extent to which they require effort on the part of the potential responders. Finally, we examine characteristics of these users and the linguistic characteristics of status upyears that contain mobilization requests. Introduction},
  author    = {Ellison, Nicole B and Gray, Rebecca and Vitak, Jessica and Lampe, Cliff and Fiore, Andrew T},
  url       = {http://www-personal.umich.edu/~enicole/Ellison\_etal\_ICWSM2013.pdf},
  booktitle = {Proceedings of the 7th annual International Conference on Weblogs and Social Media ({ICWSM})},
  year      = {2013},
  title     = {Calling all friends: Exploring requests for help on {Facebook}}
}

@inproceedings{Castillo2014,
  abstract  = {This paper presents a study of the life cycle of news articles posted online. We describe the interplay between website visitation patterns and social media reactions to news content. We show that we can use this hybrid observation method to characterize distinct classes of articles. We also find that social media reactions can help predict future visitation patterns early and accurately. We valiyear our methods using qualitative analysis as well as quantitative analysis on data from a large international news network, for a set of articles generating more than 3,000,000 visits and 200,000 social media reactions. We show that it is possible to model accurately the overall traffic articles will ultimately receive by observing the first ten to twenty minutes of social media reactions. Achieving the same prediction accuracy with visits alone would require to wait for three hours of data. We also describe significant improvements on the accuracy of the early prediction of shelf-life for news stories.},
  author    = {Castillo, Carlos and El-Haddad, Mohammed and Pfeffer, Jürgen and Stempeck, Matt},
  location  = {Baltimore, ML},
  publisher = {ACM},
  booktitle = {Proceedings of the 17th {ACM} conference on Computer supported cooperative work \& social computing},
  year      = {2014},
  doi       = {10.1145/2531602.2531623},
  title     = {Characterizing the Life Cycle of Online News Stories Using Social Media Reactions}
}

@article{Conover2012,
  author  = {Conover, Michael D and Gonçalves, Bruno and Flammini, Alessandro and Menczer, Filippo},
  year    = {2012},
  doi     = {10.1140/epjds6},
  issn    = {2193-1127},
  journal = {EPJ Data Science},
  number  = {6},
  pages   = {1--19},
  title   = {Partisan asymmetries in online political activity},
  volume  = {1}
}

@article{Ausserhofer2013,
  author  = {Ausserhofer, Julian and Maireder, Axel},
  year    = {2013},
  doi     = {10.1080/1369118X.2012.756050},
  issn    = {1369-118X},
  journal = {Information, Communication \& Society},
  number  = {3},
  pages   = {291--314},
  title   = {National Politics on {Twitter}},
  volume  = {16}
}

@article{Trilling2015,
  abstract = {While watching television, more and more citizens comment the program live on social media. This is especially interesting in the case of political debates, as viewers' comments might not only allow us to tap into public opinion, but they can also be an influential factor of their own and contribute to public discourse. This article analyzes how the TV debate between the candiyears for chancellor during the German election campaign 2013 was discussed on Twitter. To do so, the transcript of the debate is linked to a set of N = 120,557 tweets containing the hashtag {\#}tvduell. The results indicate that the candiyears were only to a minor degree successful in getting their topics to the Twitter debate. An optimistic reading of the results suggests that Twitter serves as a complement to draw attention to topics neglected in the official debate. A more pessimistic reading would point to the fact that the discourse on Twitter seems to be dominated by sarcastic or funny rather than by substantial content.},
  author   = {Trilling, D.},
  year     = {2015},
  doi      = {10.1177/0894439314537886},
  issn     = {0894-4393},
  journal  = {Social Science Computer Review},
  keywords = {election campaign,german elections,political debate,second screen,tvduell,twitter},
  number   = {3},
  pages    = {259--276},
  title    = {Two Different Debates? {I}nvestigating the Relationship Between a Political Debate on {TV} and Simultaneous Comments on {Twitter}},
  volume   = {33}
}

@misc{Madnani,
  author       = {Madnani, N.},
  year         = {2007},
  howpublished = {http://desilinguist.org/pdf/crossroads.pdf},
  title        = {Getting started on Natural Language Processing with {P}ython.}
}

@article{Bruns2013,
  author  = {Bruns, Axel and Stieglitz, Stefan},
  year    = {2013},
  doi     = {10.1080/13645579.2012.756095},
  issn    = {1364-5579},
  journal = {International Journal of Social Research Methodology},
  number  = {2},
  pages   = {91--108},
  title   = {{Towards more systematic Twitter analysis: metrics for tweeting activities}},
  volume  = {16}
}

@article{Huang2007,
  author  = {Huang, Yen-Pei and Goh, Tiong and Liew, Chern Li},
  year    = {2007},
  doi     = {10.1109/ISM.Workshops.2007.92},
  journal = {Ninth IEEE International Symposium on Multimedia Workshops (ISMW 2007)},
  pages   = {517--521},
  title   = {Hunting Suicide Notes in {Web 2.0} -- Preliminary Findings}
}

@article{Mostafa2013,
  author  = {Mostafa, Mohamed M.},
  year    = {2013},
  doi     = {10.1016/j.eswa.2013.01.019},
  issn    = {09574174},
  journal = {Expert Systems with Applications},
  number  = {10},
  pages   = {4241--4251},
  title   = {More than words: Social networks' text mining for consumer brand sentiments},
  volume  = {40}
}

@article{Pestian2012,
  author   = {Pestian, John and Matykiewicz, Pawel and Linn-Gust, Michelle and South, Brett and Uzuner, Ozlem and Wiebe, Jan and Cohen, K. Bretonnel and Hurdle, John and Brew, Christopher},
  year     = {2012},
  doi      = {10.4137/BII.S9042},
  issn     = {1178-2226},
  journal  = {Biomedical Informatics Insights},
  keywords = {1,10,16,3,4137,5,bii,biomedical informatics insights 2012,challenge 2011,com,computational linguistics,doi,from http,la-press,natural language processing,s9042,sentiment analysis,shared task,suicide,suicide notes,suppl,this article is available,www},
  pages    = {3--16},
  title    = {{Sentiment Analysis of Suicide Notes: A Shared Task}},
  volume   = {5}
}

@inproceedings{Morstatter2013,
  abstract  = {july 2013},
  author    = {Morstatter, Fred and Pfeffer, Jürgen and Liu, Huan and Carley, Kathleen M},
  location  = {Boston, MA},
  url       = {http://www.public.asu.edu/~fmorstat/paperpdfs/icwsm2013.pdf},
  booktitle = {International {AAAI} Conference on Weblogs and Social Media {(ICWSM)}},
  year      = {2013},
  title     = {Is the Sample Good Enough? Comparing Data from {Twitter's Streaming API} with {Twitter's Firehose}}
}

@article{Mahrt2013,
  author  = {Mahrt, Merja and Scharkow, Michael},
  year    = {2013},
  doi     = {10.1080/08838151.2012.761700},
  issn    = {0883-8151},
  journal = {Journal of Broadcasting \& Electronic Media},
  number  = {1},
  pages   = {20--33},
  title   = {The Value of {Big Data} in Digital Media Research},
  volume  = {57}
}

@article{Vis2013,
  author  = {Vis, Farida},
  year    = {2013},
  doi     = {10.5210/fm.v18i10.4878},
  issn    = {13960466},
  journal = {First Monday},
  number  = {10},
  pages   = {1--16},
  title   = {A critical reflection on {Big Data}: Considering {APIs}, researchers and tools as data makers},
  volume  = {18}
}

@article{boyd2012,
  abstract = {The era of Big Data has begun. Computer scientists, physicists, economists, mathematicians, political scientists, bio-informaticists, sociologists, and other scholars are clamoring for access to the massive quantities of information produced by and about people, things, and their interactions. Diverse groups argue about the potential benefits and costs of analyzing genetic sequences, social media interactions, health records, phone logs, government records, and other digital traces left by people. Significant questions emerge. Will large-scale search data help us create better tools, services, and public goods? Or will it usher in a new wave of privacy incursions and invasive marketing? Will data analytics help us understand online communities and political movements? Or will it be used to track protesters and suppress speech? Will it transform how we study human communication and culture, or narrow the palette of research options and alter what `research' means? Given the rise of Big Data as a socio-technical phenomenon, we argue that it is necessary to critically interrogate its assumptions and biases. In this article, we offer six provocations to spark conversations about the issues of Big Data: a cultural, technological, and scholarly phenomenon that rests on the interplay of technology, analysis, and mythology that provokes extensive utopian and dystopian rhetoric.},
  author   = {Boyd, Danah and Crawford, Kate},
  year     = {2012},
  doi      = {10.1080/1369118X.2012.678878},
  journal  = {Information, Communication \& Society},
  number   = {5},
  pages    = {662--679},
  title    = {Critical questions for {Big Data}},
  volume   = {15}
}

@book{McKinney2012,
  author    = {McKinney, W.},
  location  = {Sebastopol, CA},
  publisher = {O'Reilly},
  year      = {2012},
  title     = {Python for data analysis}
}

@book{Bird2009,
  author    = {Bird, S. and Loper, E. and Klein, E.},
  location  = {Sebastopol, CA},
  publisher = {O'Reilly},
  year      = {2009},
  title     = {Natural language processing with {P}ython}
}

@book{Russel2013,
  author    = {Russel, M.A.},
  location  = {Sebastopol, CA},
  publisher = {O'Reilly},
  year      = {2013},
  edition   = {2nd},
  title     = {Mining the social web. {Data} mining {Facebook, Twitter, LinkedIn, Google+, GitHub}, and more}
}

@article{Lewis2013,
  author  = {Lewis, Seth C. and Zamith, Rodrigo and Hermida, Alfred},
  year    = {2013},
  doi     = {10.1080/08838151.2012.761702},
  journal = {Journal of Broadcasting \& Electronic Media},
  number  = {1},
  pages   = {34--52},
  title   = {Content Analysis in an Era of {Big Data}: A Hybrid Approach to Computational and Manual Methods},
  volume  = {57}
}

@article{mazieres2014,
  abstract = {The development of the web has increased the diversity of pornographic content, and at the same time the rise of online platforms has initiated a new trend of quantitative research that makes possible the analysis of data on an unprecedented scale. This paper explores the application of a quantitative approach to publicly available data collected from pornographic websites. Several analyses are applied to these digital traces with a focus on keywords describing videos and their underlying categorization systems. The analysis of a large network of tags shows that the accumulation of categories does not separate scripts from each other, but instead draws a multitude of significant paths between fuzzy categories. The datasets and tools we describe have been made publicly available for further study.},
  author   = {Mazières, Antoine and Trachman, Mathieu and Cointet, Jean-Philippe and Coulmont, Baptiste and Prieur, Christophe},
  year     = {2014},
  doi      = {10.1080/23268743.2014.888214},
  journal  = {Porn Studies},
  number   = {1-2},
  pages    = {80--95},
  title    = {Deep tags: toward a quantitative analysis of online pornography},
  volume   = {1}
}

@book{VanAtteveldt2008,
  author    = {Van Atteveldt, Wouter},
  location  = {Charleston, SC},
  publisher = {BookSurge},
  year      = {2008},
  title     = {Semantic Network Analysis: {Techniques} for Extracting, Representing, and Querying Media Content}
}

@article{DeSmedt2012,
  author   = {{De Smedt}, Tom and Daelemans, W},
  year     = {2012},
  journal  = {The Journal of Machine Learning Research},
  keywords = {data mining,graph networks,machine learning,natural language processing,python},
  pages    = {2063--2067},
  title    = {{Pattern for Python}},
  volume   = {13}
}

@article{JunquedeFortuny2012,
  author  = {{Junqué de Fortuny}, Enric and {De Smedt}, Tom and Martens, David and Daelemans, Walter},
  year    = {2012},
  doi     = {10.1016/j.eswa.2012.04.013},
  issn    = {09574174},
  journal = {Expert Systems with Applications},
  number  = {14},
  pages   = {11616--11622},
  title   = {{Media coverage in times of political crisis: A text mining approach}},
  volume  = {39}
}

@article{Borra2014,
  author  = {Borra, Erik and Rieder, Bernhard},
  year    = {2014},
  doi     = {10.1108/AJIM-09-2013-0094},
  issn    = {2050-3806},
  journal = {Aslib Journal of Information Management},
  number  = {3},
  pages   = {262--278},
  title   = {Programmed method: {Developing} a toolset for capturing and analyzing tweets},
  volume  = {66}
}

@inproceedings{Rieder2013,
  author    = {Rieder, Bernhard},
  location  = {New York, NY},
  publisher = {ACM},
  booktitle = {Proceedings of the 5th Annual {ACM} Web Science Conference},
  year      = {2013},
  pages     = {346--355},
  title     = {{Studying Facebook via data extraction: The Netvizz application}}
}

@article{Boumans2016,
  author  = {Boumans, Jelle W. and Trilling, Damian},
  year    = {2016},
  doi     = {10.1080/21670811.2015.1096598},
  issn    = {2167-0811},
  journal = {Digital Journalism},
  number  = {1},
  pages   = {8--23},
  title   = {Taking stock of the toolkit: An overview of relevant autmated content analysis approaches and techniques for digital journalism scholars},
  volume  = {4}
}

@article{Jurgens2016,
  author  = {Jürgens, Pascal and Jungherr, Andreas},
  year    = {2016},
  doi     = {10.2139/ssrn.2710146},
  journal = {SSRN},
  title   = {A tutorial for using {T}witter data in the social sciences: {D}ata collection, preparation, and analysis}
}

@article{Kitchin2014,
  abstract = {This article examines how the availability of Big Data, coupled with new data analytics, challenges established epistemologies across the sciences, social sciences and humanities, and assesses the extent to which they are engendering paradigm shifts across multiple disciplines. In particular, it critically explores new forms of empiricism that declare ‘the end of theory’, the creation of data-driven rather than knowledge-driven science, and the development of digital humanities and computational social sciences that propose radically different ways to make sense of culture, history, economy and society. It is argued that: (1) Big Data and new data analytics are disruptive innovations which are reconfiguring in many instances how research is conducted; and (2) there is an urgent need for wider critical reflection within the academy on the epistemological implications of the unfolding data revolution, a task that has barely begun to be tackled despite the rapid changes in research practices presently taking place. After critically reviewing emerging epistemological positions, it is contended that a potentially fruitful approach would be the development of a situated, reflexive and contextually nuanced epistemology. Keywords},
  author   = {Kitchin, Rob},
  year     = {2014},
  doi      = {10.1177/2053951714528481},
  issn     = {2053-9517},
  journal  = {Big Data {\&} Society},
  keywords = {big data,computational,data analytics,data-driven science,digital humanities,end of theory,epistemology,paradigms},
  number   = {1},
  pages    = {1--12},
  title    = {{Big Data, new epistemologies and paradigm shifts}},
  volume   = {1}
}

@article{Lazer2009,
  abstract = {A field is emerging that leverages the capacity to collect and analyze data at a scale that may reveal patterns of individual and group behaviors.},
  author   = {Lazer, David and Pentland, Alex and Adamic, Lada and Aral, Sinan and Barabási, Albert-László and Brewer, Devon and Christakis, Nicholas and Contractor, Noshir and Fowler, James and Gutmann, Myron and Jebara, Tony and King, Gary and Macy, Michael and Roy, Deb and van Alstyne, Marshall},
  year     = {2009},
  doi      = {10.1126/science.1167742},
  issn     = {19395108},
  journal  = {Science},
  pages    = {721--723},
  title    = {Computational social science},
  volume   = {323}
}

@article{Shah2015,
  author  = {Shah, D. V. and Cappella, J. N. and Neuman, W. R.},
  year    = {2015},
  doi     = {10.1177/0002716215572084},
  issn    = {0002-7162},
  journal = {The ANNALS of the American Academy of Political and Social Science},
  number  = {1},
  pages   = {6--13},
  title   = {{Big Data}, digital media, and computational social science: {P}ossibilities and perils},
  volume  = {659}
}

@inproceedings{statsmodels,
  author    = {Seabold, Skipper and Perktold, Josef},
  booktitle = {9th {P}ython in Science Conference},
  year      = {2010},
  title     = {Statsmodels: Econometric and statistical modeling with {P}ython}
}

@misc{scipy,
  author = {Jones, Eric and Oliphant, Travis and Peterson, Pearu and others},
  url    = {http://www.scipy.org/},
  year   = {2001},
  title  = {{SciPy}: Open source scientific tools for {Python}}
}

@article{numpy,
  author  = {{Van der Walt}, Ste{\'}fan and Colbert, S Chris and Varoquaux, Gaël},
  year    = {2011},
  doi     = {10.1109/mcse.2011.37},
  journal = {Computing in Science \& Engineering},
  number  = {2},
  pages   = {22--30},
  title   = {The {NumPy} Array: A Structure for Efficient Numerical Computation},
  volume  = {13}
}

@article{matplotlib,
  author  = {Hunter, John D.},
  year    = {2007},
  doi     = {10.1109/mcse.2007.55},
  journal = {Computing in Science \& Engineering},
  number  = {3},
  pages   = {90--95},
  title   = {Matplotlib: A 2D Graphics Environment},
  volume  = {9}
}

@inproceedings{pandas,
  author    = {McKinney, Wes and others},
  booktitle = {Proceedings of the 9th Python in Science Conference},
  year      = {2010},
  pages     = {51--56},
  title     = {Data structures for statistical computing in {P}ython},
  volume    = {445}
}

@inproceedings{Hutto2014,
  author    = {Hutto, Clayton J and Gilbert, Eric},
  booktitle = {Eighth International AAAI Conference on Weblogs and Social Media},
  year      = {2014},
  title     = {Vader: A parsimonious rule-based model for sentiment analysis of social media text}
}

@inproceedings{Wilson2005,
  author       = {Wilson, Theresa and Wiebe, Janyce and Hoffmann, Paul},
  organization = {Association for Computational Linguistics},
  booktitle    = {Proceedings of the conference on human language technology and empirical methods in natural language processing},
  year         = {2005},
  pages        = {347--354},
  title        = {Recognizing contextual polarity in phrase-level sentiment analysis}
}

@book{Vanderplas2016,
  author    = {VanderPlas, Jacob},
  location  = {Sebastopol, CA},
  publisher = {O'Reilly},
  year      = {2016},
  title     = {Python data science handbook: {E}ssential tools for working with data}
}

@book{Salganik2017,
  author    = {Salganik, Matthew J.},
  location  = {Princeton, NJ},
  publisher = {Princeton University Press},
  year      = {2017},
  title     = {Bit by bit: Social research in the digital age}
}

@article{Maier2018a,
  abstract = {ABSTRACTLatent Dirichlet allocation (LDA) topic models are increasingly being used in communication research. Yet, questions regarding reliability and validity of the approach have received little attention thus far. In applying LDA to textual data, researchers need to tackle at least four major challenges that affect these criteria: (a) appropriate pre-processing of the text collection; (b) adequate selection of model parameters, including the number of topics to be generated; (c) evaluation of the model's reliability; and (d) the process of validly interpreting the resulting topics. We review the research literature dealing with these questions and propose a methodology that approaches these challenges. Our overall goal is to make LDA topic modeling more accessible to communication researchers and to ensure compliance with disciplinary standards. Consequently, we develop a brief hands-on user guide for applying LDA topic modeling. We demonstrate the value of our approach with empirical data from an ongo...},
  author   = {Maier, Daniel and Waldherr, A. and Miltner, P. and Wiedemann, G. and Niekler, A. and Keinert, A. and Pfetsch, B. and Heyer, G. and Reber, U. and Häussler, T. and Schmid-Petri, H. and Adam, S.},
  year     = {2018},
  doi      = {10.1080/19312458.2018.1430754},
  issn     = {19312466},
  journal  = {Communication Methods and Measures},
  number   = {2-3},
  pages    = {93--118},
  title    = {Applying {LDA} Topic Modeling in Communication Research: {T}oward a Valid and Reliable Methodology},
  volume   = {12}
}

@inproceedings{Tsur2015,
  abstract  = {Framing is a sophisticated form of dis- course in which the speaker tries to in- duce a cognitive bias through consis- tent linkage between a topic and a spe- cific context (frame). We build on po- litical science and communication theory and use probabilistic topic models com- bined with time series regression analy- sis (autoregressive distributed-lag models) to gain insights about the language dy- namics in the political processes. Pro- cessing four years of public statements is- sued by members of the U.S. Congress, our results provide a glimpse into the com- plex dynamic processes of framing, atten- tion shifts and agenda setting, commonly known as ‘spin'. We further provide new evidence for the divergence in party disci- pline in U.S. politics},
  author    = {Tsur, Oren and Calacci, Dan and Lazer, David},
  publisher = {ACL},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
  year      = {2015},
  pages     = {1629--1638},
  title     = {{A Frame of Mind: Using Statistical Models for Detection of Framing and Agenda Setting Campaigns}}
}

@article{Kusner2015,
  abstract = {We present the Word Mover's Distance (WMD), a novel distance function between text docu-ments. Our work is based on recent results in word embeddings that learn semantically mean-ingful representations for words from local co-occurrences in sentences. The WMD distance measures the dissimilarity between two text doc-uments as the minimum amount of distance that the embedded words of one document need to " travel " to reach the embedded words of another document. We show that this distance metric can be cast as an instance of the Earth Mover's Dis-tance, a well studied transportation problem for which several highly efficient solvers have been developed. Our metric has no hyperparameters and is straight-forward to implement. Further, we demonstrate on eight real world document classi-fication data sets, in comparison with seven state-of-the-art baselines, that the WMD metric leads to unprecedented low k-nearest neighbor docu-ment classification error rates.},
  author   = {Kusner, Matt J and Sun, Yu and Kolkin, Nicholas I and Weinberger, Kilian Q},
  year     = {2015},
  journal  = {Proceedings of The 32nd International Conference on Machine Learning},
  pages    = {957--966},
  title    = {{From Word Embeddings To Document Distances}},
  volume   = {37}
}

@article{Garg2017,
  abstract   = {Word embeddings are ubiquitous in machine learning and natural language processing. Recent works show that the ge-ometry of the word embedding captures gender stereotypes. In this paper, we develop a framework to investigate the tem-poral dynamics of gender and ethnic stereotypes by analyzing how the embedding geometry changes over time. We apply this approach to analyze embeddings trained over 100 years of text data. Moreover, we integrate U.S. Census data over the 20th century and demonstrate that dynamics of the word embedding track closely with demographic and occupation shifts over time. We systematically quantify changes in the embeddings of various classes of occupations and adjectives and their relationship to gender and ethnic groups. While the overall embedding bias has been decreasing, specific occu-pations (e.g. intellectual professions) are still associated with males and adjectives for physical appearance are closer to fe-males. We show that our approach can robustly capture global shifts – e.g. the feminist movement in the 1960s and Asian immigration into the U.S. – as well as changes in the biases associated with specific words. Temporal analysis of word embeddings thus opens up a powerful new intersection be-tween machine learning and quantitative social science. All of our data, metric and analysis tools are available on GitHub.},
  author     = {Garg, Nikhil and Schiebinger, Londa and Jurafsky, Dan and Zou, James},
  year       = {2018},
  doi        = {10.1073/pnas.1720347115},
  eprint     = {1711.08412},
  eprinttype = {arXiv},
  issn       = {0027-8424},
  journal    = {Proceedings of the National Academy of Sciences},
  number     = {16},
  pages      = {E3635--E3644},
  title      = {{Word Embeddings as a Lens to Quantify 100 Years of Gender and Ethnic Stereotypes}},
  volume     = {115}
}

@article{Vliegenthart2014,
  abstract = {In this article the advantages of aggregate level time series analysis for the study of media coverage are discussed. This type of analysis offers the opportunity to answer questions relating to causes and effects of media attention for issues and all kind of other content characteristics. Data that ask for a time series approach have become widely available during the past years, due to the rise of digital archives and social media such as Twitter and Facebook. This type of analysis allows for answering a set of interesting research questions and strong inferences about causal processes. Common challenges in time series analysis, relating to stationarity, accounting for a series' past and autoregressive conditional heteroscedasticity are discussed. Two useful approaches, ARIMA and VAR, are introduced stepwise. An empirical example, dealing with intermedia agenda-setting between different newspapers in the Netherlands, demonstrates how both techniques can be applied and how they provide insightful answers to interesting research problems.},
  author   = {Vliegenthart, Rens},
  year     = {2014},
  doi      = {10.1007/s11135-013-9899-0},
  issn     = {1573-7845},
  journal  = {Quality {\&} Quantity},
  number   = {5},
  pages    = {2427--2445},
  title    = {Moving up. {A}pplying aggregate level time series analysis in the study of media coverage},
  volume   = {48}
}

@article{Strycharz2018,
  abstract = {Published with license by Taylor {\&} Francis Group, LLC {©} 2017 [Joanna Strycharz, Nadine Strauss, and Damian Trilling] This study investigates the reciprocal relationships between the fluctuation of the closing prices of three companies listed on the Amsterdam exchange index, namely ING, Philips and Shell and online media coverage related to these firms for a period of two years (2014–2015). Automated content analysis methods were employed to analyze sentiment and emotionality and to identify corporate topics related to the companies. A positive relation of the amount of coverage and emotionality with the fluctuation of stock prices was detected for Shell and Philips. In addition, corporate topics were found to positively Granger cause stock price fluctuation, particularly for Philips. The study advances past research in showing that the prediction of stock price fluctuation based on media coverage can be improved by including sentiment, emotionality, and corporate topics. The findings inform strategic communication, and particularly investor relations, in suggesting that media attention, sentiment, and certain corporate topics are crucial when managing media relations and with regard to securing a fair evaluation of listed companies. Furthermore, the innovative research methods are useful for researchers and practitioners alike in showcasing how media coverage related to firms and their stock fluctuations can be identified and analyzed in a reproducible, hands-on and efficient manner.},
  author   = {Strycharz, Joanna and Strauss, Nadine and Trilling, Damian},
  year     = {2018},
  doi      = {10.1080/1553118X.2017.1378220},
  issn     = {1553-118X},
  journal  = {International Journal of Strategic Communication},
  number   = {1},
  pages    = {67--85},
  title    = {{The role of media coverage in explaining stock market fluctuations: Insights for strategic financial communication}},
  volume   = {12}
}

@article{Burscher2014,
  author  = {Burscher, Björn and Odijk, Daan and Vliegenthart, Rens and de Rijke, Maarten and de Vreese, Claes H.},
  year    = {2014},
  doi     = {10.1080/19312458.2014.937527},
  issn    = {1931-2458},
  journal = {Communication Methods and Measures},
  number  = {3},
  pages   = {190--206},
  title   = {Teaching the computer to code frames in news: {C}omparing two supervised machine learning approaches to frame analysis},
  volume  = {8}
}

@article{burscher2016,
  abstract = {Methods to automatically analyze media content are advancing significantly. Among others, it has become increasingly popular to analyze the framing of news articles by means of statistical procedures. In this article, we investigate the conceptual validity of news frames that are inferred by a combination of k-means cluster analysis and automatic sentiment analysis. Furthermore, we test a way of improving statistical frame analysis such that revealed clusters of articles reflect the framing concept more closely. We do so by only using words from an article’s title and lead and by excluding named entities and words with a certain part of speech from the analysis. To valiyear revealed frames, we manually analyze samples of articles from the extracted clusters. Findings of our tests indicate that when following the proposed feature selection approach, the resulting clusters more accurately discriminate between articles with a different framing. We discuss the methodological and theoretical implications of our findings.},
  author   = {Burscher, Bjorn and Vliegenthart, Rens and {de Vreese}, Claes H.},
  year     = {2016},
  doi      = {10.1177/0894439315596385},
  journal  = {Social Science Computer Review},
  number   = {5},
  pages    = {530--545},
  title    = {Frames Beyond Words: {A}pplying Cluster and Sentiment Analysis to News Coverage of the Nuclear Power Issue},
  volume   = {34}
}

@article{GonzalezBailon2015,
  abstract = {This study offers a systematic comparison of automated content analysis tools. The ability of different lexicons to correctly identify affective tone (e.g., positive vs. negative) is assessed in different social media environments. Our comparisons examine the reliability and validity of publicly available, off-the-shelf classifiers. We use datasets from a range of online sources that vary in the diversity and formality of the language used, and we apply different classifiers to extract information about the affective tone in these datasets. We first measure agreement (reliability test) and then compare their classifications with the benchmark of human coding (validity test). Our analyses show that validity and reliability vary with the formality and diversity of the text; we also show that ready-to-use methods leave much space for improvement when analyzing domain-specific content and that a machine-learning approach offers more accurate predictions across communication domains.},
  author   = {Gonzalez-Bailon, S. and Paltoglou, G.},
  url      = {http://ann.sagepub.com/content/659/1/95.abstract?rss=1},
  year     = {2015},
  doi      = {10.1177/0002716215569192},
  issn     = {0002-7162},
  journal  = {The ANNALS of the American Academy of Political and Social Science},
  keywords = {analysis,content analysis,diversity,information,language formality,lexicon-based methods,machine,sentiment,text mining},
  number   = {1},
  pages    = {95--107},
  title    = {{Signals of Public Opinion in Online Communication: A Comparison of Methods and Data Sources}},
  volume   = {659}
}

@article{Vermeer2019,
  author   = {Vermeer, Susan and Araujo, Theo and Bernritter, Stefan F. and van Noort, Guda},
  year     = {2019},
  doi      = {10.1016/j.ijresmar.2019.01.010},
  issn     = {01678116},
  journal  = {International Journal of Research in Marketing},
  keywords = {Automated content analysis,Digital marketing strategies,Machine learning,Sentiment analysis,Social media,Webcare,eWOM},
  number   = {3},
  pages    = {492--508},
  title    = {{Seeing the wood for the trees: How machine learning can help firms in identifying relevant electronic word-of-mouth in social media}},
  volume   = {36}
}

@article{Welbers2018,
  author  = {Welbers, Kasper and Opgenhaffen, Michaël and Janssens, Marie-Christine},
  year    = {2018},
  journal = {Tijdschrift voor Communicatiewetenschap},
  number  = {1},
  pages   = {25--40},
  title   = {{Scrapers , API's en data-archieven}},
  volume  = {46}
}

@book{cssbook,
  author    = {{van Atteveldt}, Wouter and Trilling, Damian and {Arcila Calderón}, Carlos},
  location  = {Hoboken, NJ},
  publisher = {Wiley},
  year      = {2022},
  title     = {Computational analysis of communication: A practical introduction to the analysis of texts, networks, and images with code examples in Python and R}
}

@article{Hilbert2019,
  author  = {Hilbert, Martin and Barnett, George and Blumenstock, Joshua and Contractor, Noshir and Diesner, Jana and Frey, Seth and González-Bailón, Sandra and Lamberso, PJ and Pan, Jennifer and Peng, Tai-Quan and Shen, Cuihua and Smaldino, Paul E and {Van Atteveldt}, Wouter and Waldherr, Annie and Zhang, Jingwen and Zhu, Jonathan J H},
  year    = {2019},
  journal = {International Journal of Communication},
  pages   = {3912--3934},
  title   = {{Computational Communication Science : A Methodological Catalyzer for a Maturing Discipline}},
  volume  = {13}
}

@article{VanAtteveldt2018a,
  abstract = {ABSTRACTThe recent increase in digitally available data, tools, and processing power is fostering the use of computational methods to the study of communication. This special issue discusses the validity of using big data in communication science and showcases a number of new methods and applications in the fields of text and network analysis. Computational methods have the potential to greatly enhance the scientific study of communication because they allow us to move towards collaborative large-N studies of actual behavior in its social context. This requires us to develop new skills and infrastructure and meet the challenges of open, valid, reliable, and ethical “big data” research. By bringing together a number of leading scholars in one issue, we contribute to the increasing development and adaptation of computational methods in communication science.},
  author   = {van Atteveldt, Wouter and Peng, Tai Quan},
  year     = {2018},
  doi      = {10.1080/19312458.2018.1458084},
  journal  = {Communication Methods and Measures},
  number   = {2-3},
  pages    = {81--92},
  title    = {{When Communication Meets Computation: Opportunities, Challenges, and Pitfalls in Computational Communication Science}},
  volume   = {12}
}

@book{Hovy2020,
  author    = {Hovy, Dirk},
  location  = {Cambridge, UK},
  publisher = {Cambridge University Press},
  year      = {2020},
  doi       = {10.1017/9781108873352},
  title     = {Text Analysis in {P}ython for Social Scientists: Discovery and Exploration}
}

@misc{gartner,
  author = {Gartner},
  url    = {https://www.gartner.com/en/information-technology/glossary/big-data},
  year   = {2012},
  title  = {Big Data}
}

@article{VanAtteveldt2019,
  author  = {{van Atteveldt}, Wouter and Strycharz, Joanna and Trilling, Damian and Welbers, Kasper},
  year    = {2019},
  journal = {International Journal of Communication},
  pages   = {3935--3954},
  title   = {{Toward Open Computational Communication Science : A Practical Road Map for Reusable Data and Code University of Amsterdam , the Netherlands}},
  volume  = {13}
}

@misc{nelagt2018,
  author  = {Nørregaard, Jeppe and Horne, Benjamin Douglas and Adali, Sibel},
  url     = {https://doi.org/10.7910/DVN/ULHLCB},
  year    = {2019},
  doi     = {10.7910/DVN/ULHLCB},
  note    = {Dataset for article "NELA-GT-2018: A Large Multi-Labelled News Dataset for the Study of Misinformation in News Articles". (2019-01-15)},
  title   = {{NELA-GT-2018}},
  version = {V4}
}

@article{Haselmayer2017,
  abstract = {? 2016 The Author(s)Sentiment is important in studies of news values, public opinion, negative campaigning or political polarization and an explosive expansion of digital textual data and fast progress in automated text analysis provide vast opportunities for innovative social science research. Unfortunately, tools currently available for automated sentiment analysis are mostly restricted to English texts and require considerable contextual adaption to produce valid results. We present a procedure for collecting fine-grained sentiment scores through crowdcoding to build a negative sentiment dictionary in a language and for a domain of choice. The dictionary enables the analysis of large text corpora that resource-intensive hand-coding struggles to cope with. We calculate the tonality of sentences from dictionary words and we valiyear these estimates with results from manual coding. The results show that the crowdbased dictionary provides efficient and valid measurement of sentiment. Empirical examples illustrate its use by analyzing the tonality of party statements and media reports.},
  author   = {Haselmayer, Martin and Jenny, Marcelo},
  year     = {2017},
  doi      = {10.1007/s11135-016-0412-4},
  issn     = {0033-5177},
  journal  = {Quality {\&} Quantity},
  keywords = {Crowdcoding,Media negativity,Negative campaigning,Political communication,Sentiment analysis},
  number   = {6},
  pages    = {2623--2646},
  title    = {{Sentiment analysis of political communication: combining a dictionary approach with crowdcoding}},
  volume   = {51}
}

@article{Boukes2020,
  abstract = {This article scrutinizes the method of automated content analysis to measure the tone of news coverage. We compare a range of off-the-shelf sentiment analysis tools to manually coded economic news as well as examine the agreement between these dictionary approaches themselves. We assess the performance of five off-the-shelf sentiment analysis tools and two tailor-made dictionary-based approaches. The analyses result in five conclusions. First, there is little overlap between the off-the-shelf tools; causing wide divergence in terms of tone measurement. Second, there is no stronger overlap with manual coding for short texts (i.e., headlines) than for long texts (i.e., full articles). Third, an approach that combines individual dictionaries achieves a comparably good performance. Fourth, precision may increase to acceptable levels at higher levels of granularity. Fifth, performance of dictionary approaches depends more on the number of relevant keywords in the dictionary than on the number of valenced words as such; a small tailor-made lexicon was not inferior to large established dictionaries. Altogether, we conclude that off-the-shelf sentiment analysis tools are mostly unreliable and unsuitable for research purposes–at least in the context of Dutch economic news–and manual validation for the specific language, domain, and genre of the research project at hand is always warranted.},
  author   = {Boukes, Mark and van de Velde, Bob and Araujo, Theo and Vliegenthart, Rens},
  url      = {https://www.tandfonline.com/doi/full/10.1080/19312458.2019.1671966},
  year     = {2020},
  doi      = {10.1080/19312458.2019.1671966},
  issn     = {1931-2458},
  journal  = {Communication Methods and Measures},
  number   = {2},
  pages    = {83--104},
  title    = {{What's the Tone? Easy Doesn't Do It: Analyzing Performance and Agreement Between Off-the-Shelf Sentiment Analysis Tools}},
  volume   = {14}
}

@article{vanatteveldt20,
  author  = {{Van Atteveldt}, Wouter and {Van der Velden}, Mariken A.C.G. and Boukes, Mark},
  year    = {2020},
  journal = {Computational Methods and Measures},
  title   = {The Validity of Sentiment Analysis: {C}omparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms}
}

@misc{Pennebaker2007,
  author   = {Pennebaker, J. W. and Booth, R. J. and Francis, M. E.},
  location = {Austin; TX},
  year     = {2007},
  title    = {{Linguistic Inquiry and Word Count: LIWC}}
}

@article{VanAtteveldt2021,
  abstract = {Sentiment is central to many studies of communication science, from negativity and polarization in political communication to analyzing product reviews and social media comments in other sub-fields. This study provides an exhaustive comparison of sentiment analysis methods, using a validation set of Dutch economic headlines to compare the performance of manual annotation, crowd coding, numerous dictionaries and machine learning using both traditional and deep learning algorithms. The three main conclusions of this article are that: (1) The best performance is still attained with trained human or crowd coding; (2) None of the used dictionaries come close to acceptable levels of validity; and (3) machine learning, especially deep learning, substantially outperforms dictionary-based methods but falls short of human performance. From these findings, we stress the importance of always validating automatic text analysis methods before usage. Moreover, we provide a recommended step-by-step approach for (automated) text analysis projects to ensure both efficiency and validity.},
  author   = {van Atteveldt, Wouter and van der Velden, Mariken A.C.G. and Boukes, Mark},
  url      = {https://doi.org/10.1080/19312458.2020.1869198},
  year     = {2021},
  doi      = {10.1080/19312458.2020.1869198},
  issn     = {19312466},
  journal  = {Communication Methods and Measures},
  keywords = {Automated Approaches,Evaluation,Manual Annotation,Measurement,Sentiment Analysis,Validity},
  number   = {00},
  pages    = {1--20},
  title    = {{The Validity of Sentiment Analysis:Comparing Manual Annotation, Crowd-Coding, Dictionary Approaches, and Machine Learning Algorithms}},
  volume   = {00}
}

@article{Burscher2015,
  author  = {Burscher, Björn and Vliegenthart, Rens and {De Vreese}, C. H.},
  year    = {2015},
  doi     = {10.1177/0002716215569441},
  issn    = {0002-7162},
  journal = {The ANNALS of the American Academy of Political and Social Science},
  number  = {1},
  pages   = {122--131},
  title   = {{Using supervised machine learning to code policy issues: Can classifiers generalize across contexts?}},
  volume  = {659}
}

@article{Vermeer2020c,
  abstract = {The complexity and diversity of today's media landscape provides many challenges for scholars studying online news consumption. Yet it is unclear how news consumers navigate online. Moving forward, we used a custom-built browser plug-in—passively tracking Dutch online news consumers 24/7—to examine how context (website) and content (news topic) features affect patterns of online news consumption. This resulted in a data set containing more than one million Web pages, from 175 websites (news websites, search engines, social media), collected over 8 months in 2017/18. We used automated content analysis to retrieve news topics, and estimated Markov chains to detect consumption patterns. Our findings indicate that news consumers often directly visit their favorite (typically mainstream) news outlet, and continue browsing within that outlet. We also found a strong preference for entertainment news over any other topic. Although social media often offer entertainment news, they are not necessarily the starting point to such news.},
  author   = {Vermeer, Susan and Trilling, Damian and Kruikemeier, Sanne and de Vreese, Claes},
  url      = {https://doi.org/10.1080/21670811.2020.1767509},
  year     = {2020},
  doi      = {10.1080/21670811.2020.1767509},
  issn     = {2167082X},
  journal  = {Digital Journalism},
  keywords = {Markov chains,Online news consumption,entertainment news,political news,social media,supervised machine learning},
  number   = {9},
  pages    = {1114--1141},
  title    = {{Online News User Journeys: The Role of Social Media, News Websites, and Topics}},
  volume   = {8}
}

@article{Hopkins2010,
  author  = {Hopkins, Daniel J. and King, Gary},
  year    = {2010},
  journal = {American Journal of Political Science},
  number  = {1},
  pages   = {229--247},
  title   = {{A method of automated nonparametric content analysis for social science}},
  volume  = {54}
}

@article{Trilling2021,
  author  = {Trilling, Damian and {van Hoof}, Marieke},
  year    = {2020},
  doi     = {10.1080/21670811.2020.1839352},
  issue   = {10},
  journal = {Digital Journalism},
  pages   = {1317--1337},
  title   = {Between article and topic: News events as level of analysis and their computational identification},
  volume  = {8}
}

@article{Traag2019,
  abstract = {Community detection is often used to understand the structure of large and complex networks. One of the most popular algorithms for uncovering community structure is the so-called Louvain algorithm. We show that this algorithm has a major defect that largely went unnoticed until now: the Louvain algorithm may yield arbitrarily badly connected communities. In the worst case, communities may even be disconnected, especially when running the algorithm iteratively. In our experimental analysis, we observe that up to 25{\%} of the communities are badly connected and up to 16{\%} are disconnected. This may present serious issues in subsequent analyses. To address this problem, we introduce the Leiden algorithm. We prove that the Leiden algorithm yields communities that are guaranteed to be connected. In addition, we prove that, when the Leiden algorithm is applied iteratively, it converges to a partition in which all subsets of all communities are locally optimally assigned. Furthermore, by relying on a fast local move approach, the Leiden algorithm runs faster than the Louvain algorithm. We demonstrate the performance of the Leiden algorithm for several benchmark and real-world networks. We find that the Leiden algorithm is faster than the Louvain algorithm and uncovers better partitions, in addition to providing explicit guarantees. Based on our results, we conclude that the Leiden algorithm is preferable to the Louvain algorithm.},
  author   = {Traag, V. A. and Waltman, L. and van Eck, N. J.},
  year     = {2019},
  doi      = {10.1038/s41598-019-41695-z},
  issn     = {20452322},
  journal  = {Scientific Reports},
  number   = {1},
  pages    = {1--12},
  title    = {{From Louvain to Leiden: guaranteeing well-connected communities}},
  volume   = {9}
}

@article{Traag2015,
  author  = {Traag, V. A. and Aldecoa, R. and Delvenne, J.-C.},
  year    = {2015},
  doi     = {10.1103/physreve.92.022816},
  journal = {Physical Review E},
  number  = {2},
  title   = {Detecting communities using asymptotical surprise},
  volume  = {92}
}

@inproceedings{Nothman2018,
  abstract  = {Open-source software (OSS) packages for natural language processing often include stop word lists. Users may apply them without awareness of their surprising omissions (e.g. hasn't but not hadn't) and inclusions (e.g. computer), or their incompatibility with particular tokenizers. Motivated by issues raised about the Scikit-learn stop list, we investigate variation among and consistency within 52 popular English-language stop lists, and propose strategies for mitigating these issues.},
  author    = {Nothman, Joel and Qin, Hanmin and Yurchak, Roman},
  location  = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  booktitle = {Proceedings of Workshop for NLP Open Source Software (NLP-OSS)},
  year      = {2018},
  doi       = {10.18653/v1/W18-2502},
  pages     = {7--12},
  title     = {{Stop Word Lists in Free Open-source Software Packages}}
}

@article{3bij3,
  abstract = {Abstract Today's online news environment is increasingly characterized by personalized news selections, relying on algorithmic solutions for extracting relevant articles and composing an individual's news diet. Yet, the impact of such recommendation algorithms on how we consume and perceive news is still understudied. We therefore developed one of the first software solutions to conduct studies on effects of news recommender systems in a realistic setting. The web app of our framework (called 3bij3) displays real-time news articles selected by different mechanisms. 3bij3 can be used to conduct large-scale field experiments, in which participants' use of the site can be tracked over extended periods of time. Compared to previous work, 3bij3 gives researchers control over the recommendation system under study and creates a realistic environment for the participants. It integrates web scraping, different methods to compare and classify news articles, different recommender systems, a web interface for participants, gamification elements, and a user survey to enrich the behavioural measures obtained.},
  author   = {Loecherbach, Felicia and Trilling, Damian},
  year     = {2020},
  doi      = {10.5117/CCR2020.1.003.LOEC},
  issn     = {2665-9085},
  journal  = {Computational Communication Research},
  number   = {1},
  pages    = {53--79},
  title    = {{3bij3 ‐ Developing a framework for researching recommender systems and their effects}},
  volume   = {2}
}

@inproceedings{Bender2021,
  abstract  = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  author    = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  publisher = {Association for Computing Machinery},
  booktitle = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  year      = {2021},
  doi       = {10.1145/3442188.3445922},
  isbn      = {9781450383097},
  number    = {1},
  pages     = {610--623},
  title     = {{On the dangers of stochastic parrots: Can language models be too big?}},
  volume    = {1}
}

@article{Bolukbasi2016,
  author  = {Bolukbasi, Tolga and Chang, Kai-Wei and Zou, James Y and Saligrama, Venkatesh and Kalai, Adam T},
  year    = {2016},
  journal = {Advances in neural information processing systems},
  pages   = {4349--4357},
  title   = {Man is to computer programmer as woman is to homemaker? debiasing word embeddings},
  volume  = {29}
}

@article{Greussing2017,
  author  = {Greussing, Esther and Boomgaarden, Hajo G.},
  year    = {2017},
  doi     = {10.1080/1369183X.2017.1282813},
  issn    = {14699451},
  journal = {Journal of Ethnic and Migration Studies},
  number  = {11},
  pages   = {1749--1774},
  title   = {{Shifting the refugee narrative? An automated frame analysis of Europe's 2015 refugee crisis}},
  volume  = {43}
}

@article{Levy2018,
  abstract = {Recent trends suggest that neural-network-inspired word embedding models outperform traditional count-based distri-butional models on word similarity and analogy detection tasks. We reveal that much of the performance gains of word embeddings are due to certain system design choices and hyperparameter op-timizations, rather than the embedding algorithms themselves. Furthermore, we show that these modifications can be transferred to traditional distributional models, yielding similar gains. In contrast to prior reports, we observe mostly local or insignificant performance differences between the methods, with no global advantage to any single approach over the others.},
  author   = {Levy, Omer and Goldberg, Yoav and Dagan, Ido},
  year     = {2018},
  doi      = {10.1162/tacl_a_00134},
  journal  = {Transactions of the Association for Computational Linguistics},
  pages    = {211--225},
  title    = {{Improving Distributional Similarity with Lessons Learned from Word Embeddings}},
  volume   = {3}
}

@article{Firth1957,
  author  = {Firth, John R},
  year    = {1957},
  journal = {Studies in linguistic analysis},
  title   = {A synopsis of linguistic theory, 1930-1955}
}

@article{Rudkowsky2018a,
  abstract = {Moving beyond the dominant bag-of-words approach to sentiment analysis we introduce an alternative procedure based on distributed word embed- dings. The strength of word embeddings is the ability to capture similarities in word meaning. We use word embeddings as part of a supervised machine learning procedure which estimates levels of negativity in parlia- mentary speeches. The procedure's accuracy is evaluated with crowdcoded training sentences; its external validity through a study of patterns of negativity in Austrian parliamentary speeches. The results show the poten- tial of the word embeddings approach for sentiment analysis in the social sciences. Introduction},
  author   = {Rudkowsky, Elena and Haselmayer, Martin and Wastian, Matthias and Jenny, Marcelo and Emrich, Štefan and Sedlmair, Michael},
  url      = {https://doi.org/10.1080/19312458.2018.1455817},
  year     = {2018},
  doi      = {10.1080/19312458.2018.1455817},
  issn     = {19312466},
  journal  = {Communication Methods and Measures},
  number   = {2-3},
  pages    = {140--157},
  title    = {{More than Bags of Words: Sentiment Analysis with Word Embeddings}},
  volume   = {12}
}

@article{Kroon2021,
  author  = {Kroon, Anne C. and Trilling, Damian and Raats, Tamara},
  year    = {2021},
  doi     = {10.1177/1077699020932304},
  issue   = {2},
  journal = {Journalism \& Mass Communication Quarterly},
  pages   = {451--477},
  title   = {Guilty by association: {U}sing word embeddings to measure ethnic stereotypes in news coverage},
  volume  = {98}
}

@article{Casas2022,
  author  = {Casas, Andreu and Williams, Nora Webb},
  year    = {2022},
  doi     = {10.5117/ccr2022.1.000.casa},
  journal = {Computational Communication Research},
  number  = {1},
  title   = {Introduction to the Special Issue on Images as Data},
  volume  = {4}
}

@book{Webbwilliams2020,
  author    = {Webb Williams, Nora and Casas, Andreu and Wilkerson, John D.},
  publisher = {Cambridge University Press},
  year      = {2020},
  doi       = {10.1017/9781108860741},
  series    = {Elements in Quantitative and Computational Methods for the Social Sciences},
  title     = {Images as Data for Social Science Research: An Introduction to Convolutional Neural Nets for Image Classification}
}

@article{Chen2022,
  author  = {Chen, Kaiping and Kim, Sang Jung and Gao, Qiantong and Raschka, Sebastian},
  year    = {2022},
  doi     = {10.5117/ccr2022.1.003.chen},
  journal = {Computational Communication Research},
  number  = {1},
  pages   = {98--134},
  title   = {Visual Framing of Science Conspiracy Videos},
  volume  = {4}
}

@article{Jurgens2022,
  author  = {Jürgens, Pascal and Meltzer, Christine E. and Scharkow, Michael},
  year    = {2022},
  doi     = {10.5117/ccr2022.1.005.jurg},
  journal = {Computational Communication Research},
  number  = {1},
  pages   = {173--207},
  title   = {Visual Framing of Science Conspiracy Videos},
  volume  = {4}
}

@article{Joo2022,
  author  = {Joo, Jungseock and Steinert-Threlkeld, Zachary C.},
  year    = {2022},
  doi     = {10.5117/ccr2022.1.001.joo},
  journal = {Computational Communication Research},
  number  = {1},
  pages   = {11--67},
  title   = {Image as Data: Automated Content Analysis for Visual Presentations of Political Actors and Events},
  volume  = {4}
}

@article{Araujo2020b,
  abstract = {The increasing volume of images published online in a wide variety of contexts requires communication researchers to address this reality by analyzing visual content at a large scale. Ongoing advances in computer vision to automatically detect objects, concepts, and features in images provide a promising opportunity for communication research. We propose a research protocol for Automated Visual Content Analysis (AVCA) to enable large-scale content analysis of images. It offers inductive and deductive ways to use commercial pre-trained models for theory building in communication science. Using the example of corporations' website images on sustainability, we show in a step-by-step fashion how to classify a large sample (N = 21,876) of images with unsupervised and supervised machine learning, as well as custom models. The possibilities and pitfalls of these approaches are discussed, ethical issues are addressed, and application examples for future communication research are detailed.},
  author   = {Araujo, Theo and Lock, Irina and van de Velde, Bob},
  year     = {2020},
  doi      = {10.1080/19312458.2020.1810648},
  issn     = {1931-2458},
  journal  = {Communication Methods and Measures},
  number   = {4},
  pages    = {239--265},
  title    = {Automated Visual Content Analysis {(AVCA)} in Communication Research: A Protocol for Large Scale Image Classification with Pre-Trained Computer Vision Models},
  volume   = {14}
}

@incollection{Bock2011,
  author    = {Bock, Annekatrin and Isermann, Holger and Knieper, Thomas},
  publisher = {SAGE Publications Ltd},
  year      = {2011},
  booktitle = {The SAGE handbook of visual research methods},
  pages     = {265--282},
  title     = {Quantitative Content Analysis of the Visual},
  editor    = {Margolis, Eric and Pauwels, Luc}
}

@misc{Baevski2022,
  abstract   = {While the general idea of self-supervised learning is identical across modalities, the actual algorithms and objectives differ widely because they were developed with a single modality in mind. To get us closer to general self-supervised learning, we present data2vec, a framework that uses the same learning method for either speech, NLP or computer vision. The core idea is to predict latent representations of the full input data based on a masked view of the input in a self-distillation setup using a standard Transformer architecture. Instead of predicting modality-specific targets such as words, visual tokens or units of human speech which are local in nature, data2vec predicts contextualized latent representations that contain information from the entire input. Experiments on the major benchmarks of speech recognition, image classification, and natural language understanding demonstrate a new state of the art or competitive performance to predominant approaches.},
  author     = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  url        = {http://arxiv.org/abs/2202.03555},
  year       = {2022},
  eprint     = {2202.03555},
  eprinttype = {arXiv},
  title      = {{data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language}}
}

@article{Grootendorst2022,
  author  = {Grootendorst, Maarten},
  year    = {2022},
  journal = {arXiv preprint arXiv:2203.05794},
  title   = {BERTopic: Neural topic modeling with a class-based TF-IDF procedure}
}

@inproceedings{Lin2023,
  author    = {Lin, Zilin and Welbers, Kasper and Vermeer, Susan and Trilling, Damian},
  booktitle = {{International Conference on the Web and Social Media (ICWSM)}},
  year      = {2023},
  note      = {\url{https://arxiv.org/abs/2212.04185}},
  title     = {Beyond discrete genres: {M}apping news items onto a multidimensional framework of genre cues}
}

@inproceedings{Vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  editor    = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2017},
  title     = {Attention is All you Need},
  volume    = {30}
}

@article{Devlin2018,
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year    = {2018},
  journal = {arXiv preprint arXiv:1810.04805},
  title   = {Bert: Pre-training of deep bidirectional transformers for language understanding}
}

@article{Leydesdorff2017,
  abstract = {(Open Nottingham OER report; survey of 51 undergraduates' use of OER.)},
  author   = {Leydesdorff, Loet and Nerghes, Adina},
  year     = {2017-04},
  doi      = {10.1002/asi.23740},
  issn     = {23301635},
  journal  = {Journal of the Association for Information Science and Technology},
  keywords = {OER,Open educational resources,Open learning,Open textbooks},
  note     = {arXiv: 0803.1716 ISBN: 9783848215430},
  number   = {4},
  pages    = {1024--1035},
  title    = {Co-word maps and topic modeling: {A} comparison using small and medium-sized corpora ( {N} {<} 1,000)},
  volume   = {68}
}

@article{Blei2003,
  author  = {Blei, DM and Ng, AY and Jordan, MI},
  year    = {2003},
  journal = {Journal of machine Learning research},
  pages   = {993--1022},
  title   = {Latent dirichlet allocation},
  urlyear = {2015-01-14},
  volume  = {3}
}

@inproceedings{Blei2006,
  author    = {Blei, David M and Lafferty, John D},
  booktitle = {Proceedings of the 23rd international conference on Machine learning},
  year      = {2006},
  pages     = {113--120},
  title     = {Dynamic topic models}
}

@article{Roberts2014,
  author  = {Roberts, Margaret E and Stewart, Brandon M and Tingley, Dustin and Lucas, Christopher and Leder-Luis, Jetson and Gadarian, Shana Kushner and Albertson, Bethany and Rand, David G},
  year    = {2014},
  journal = {American journal of political science},
  number  = {4},
  pages   = {1064--1082},
  title   = {Structural topic models for open-ended survey responses},
  volume  = {58}
}

@inproceedings{bianchi-etal-2021-cross,
  author    = {Bianchi, Federico and Terragni, Silvia and Hovy, Dirk and Nozza, Debora and Fersini, Elisabetta},
  location  = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2021.eacl-main.143},
  booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
  year      = {2021-04},
  pages     = {1676--1683},
  title     = {Cross-lingual Contextualized Topic Models with Zero-shot Learning}
}

@inproceedings{bianchi-etal-2021-pre,
  author    = {Bianchi, Federico and Terragni, Silvia and Hovy, Dirk},
  location  = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.acl-short.96},
  booktitle = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  year      = {2021-08},
  doi       = {10.18653/v1/2021.acl-short.96},
  pages     = {759--766},
  title     = {Pre-training is a Hot Topic: Contextualized Document Embeddings Improve Topic Coherence}
}

@article{angelov2020top2vec,
  author  = {Angelov, Dimo},
  year    = {2020},
  journal = {arXiv preprint arXiv:2008.09470},
  title   = {Top2vec: Distributed representations of topics}
}

@inproceedings{radford2021clip,
  abstract  = {State-of-the-art computer vision systems are trained to predict a fixed set of predetermined object categories. This restricted form of supervision limits their generality and usability since additional labeled data is needed to specify any other visual concept. Learning directly from raw text about images is a promising alternative which leverages a much broader source of supervision. We demonstrate that the simple pre-training task of predicting which caption goes with which image is an efficient and scalable way to learn SOTA image representations from scratch on a dataset of 400 million (image, text) pairs collected from the internet. After pre-training, natural language is used to reference learned visual concepts (or describe new ones) enabling zero-shot transfer of the model to downstream tasks. We study the performance of this approach by benchmarking on over 30 different existing computer vision datasets, spanning tasks such as OCR, action recognition in videos, geo-localization, and many types of fine-grained object classification. The model transfers non-trivially to most tasks and is often competitive with a fully supervised baseline without the need for any dataset specific training. For instance, we match the accuracy of the original ResNet-50 on ImageNet zero-shot without needing to use any of the 1.28 million training examples it was trained on.},
  author    = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
  editor    = {Meila, Marina and Zhang, Tong},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v139/radford21a.html},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning},
  year      = {2021},
  file      = {http://proceedings.mlr.press/v139/radford21a/radford21a.pdf},
  pages     = {8748--8763},
  series    = {Proceedings of Machine Learning Research},
  title     = {Learning Transferable Visual Models From Natural Language Supervision},
  volume    = {139}
}

