\input{../../resources/preamble}
\addbibresource{../../resources/literature.bib}
\graphicspath{{../../resources/img/}}


\begin{document}

\title[Big Data and Automated Content Analysis]{\textbf{Big Data and Automated Content Analysis (12EC)} 
\\Week 9: »Transformers«
\\Friday}
\author[Damian Trilling]{Damian Trilling\\ \footnotesize{d.c.trilling@uva.nl, @damian0604 \\}}
\date{April 12, 2023}
\institute[UvA CW]{UvA RM Communication Science}


\begin{frame}{}
	\titlepage
\end{frame}

\begin{frame}{Today}
	\tableofcontents
\end{frame}
\begin{frame}[standout]
Before we start: Questions from last week?
\end{frame}


\begin{frame}[standout]
Today: From word embeddings via neural networks towards Transformers
\end{frame}

\question{Remember what we discussed about the move from BOW to word embeddings?}

% deze was eigenlijk voor week 8 gepland, maar zijn we niet aan toegekomen
\input{../../modules/machinelearning-text/neuralnetworks.tex}

\begin{frame}{Let's look into some code}
\url{https://github.com/uvacw/teaching-bdaca/blob/main/12ec-course/week08/exercises/06downstreamkeras.ipynb}
\end{frame}

\input{../../modules/machinelearning-text/transformers.tex}


\begin{frame}[standout]
Let's look into Google Colab!
\end{frame}


\section{Next steps}
\begin{frame}[standout]
Try it yourself!
\url{https://github.com/uvacw/teaching-bdaca/blob/main/12ec-course/week09/exercises/README.md}
\end{frame}


\begin{frame}[allowframebreaks,plain]
\printbibliography
\end{frame}



\end{document}
