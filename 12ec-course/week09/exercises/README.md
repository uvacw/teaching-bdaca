# Exercises week 9

## Finetuning a transformer.

Have a look at this  [notebook](../../../modules/machinelearning-text-exercises/transformers_bert_classification.ipynb).

You probably want to do this on GoogleColab (or somewhere else where you have a GPU)

## At home: 

Take a look at this video made by Moritz Laurer (former VU PhD, now working at Huggingface) who gives a hands-on workshop into Huggingface, transformers, and fine-tuning. You can find the video here: [Hands-on Transformers](https://www.youtube.com/watch?v=iCzE94oAEvI) The video is quite long, so here are the parts I recommend: 

15:40 - 45:00 Introduction to NLP Open Source Toolkit (Huggingface) \
1:00:40 - 1:15:00 Transfer Learning \
1:22:00 - 1:36:00 Inside Transformers \
1:45:00 - 2:12:00 Fine-tuning Bert

In-between these videos there are often additional Q&A's, you do not have to watch those (but of course you can if you think it might help you). All the materials he is using you can find here [GitHub Transformers](https://github.com/MoritzLaurer/summer-school-transformers-2023). I do not recommend running all the code yourself as some of it takes a lot of resources/time to run, rather follow along with him in the video. 

The rest of the video has the following sections (you can watch them if interested but it is NOT required)

2:32:30 - 2:54:00 Fine-tuning Bert-NLI \
3:02:30 - 3:19:00 Data centric AI \
3:24:00 - 3:41 Annotation with Argilla \
3:41:00 - 3:54:00 Fine-tuning generative LLMs

